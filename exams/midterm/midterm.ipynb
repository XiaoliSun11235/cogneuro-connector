{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuro DS Midterm\n",
    "This midterm will cover the material that we discussed in the first 5 weeks of class. It will take the methods that we've covered thus far into a new dataset, in order to see if there is something that we can learn from the reults.\n",
    "\n",
    "# Remember\n",
    "* Make sure you use `%matplotlib inline` before calling any plots that aren't interactive. When you upload a PDF of the midterm, we *need* to see the plots.\n",
    "* When you're writing code, don't make the code extend beyond the visible code block. If you need to write more, hit enter and continue on the next line. If you're writing a comment (e.g. answering a conceptual question), then just start a new line.\n",
    "* to submit this homework, **submit both a PDF and the raw jupyter notebook file** to the assignment page on bCourses\n",
    "\n",
    "# The Dataset\n",
    "The dataset that we'll use comes from a (different) electrocorticography patient. The subject had intractible epilepsy, which required surgery in order to address. A common problem with neurosurgery is that we don't know *exactly* which regions of the brain are crucial for performing some function. For example, we may know the general region that processes to sounds, but in each individual it'll be a little difference.\n",
    "\n",
    "To deal with this, doctors often use *localizers* to determine where a particular region is in one person. This surgeon in particular was interested in a region of the brain called the *Fusiform Face Area* (FFA), a well-studied part of the visual system that seems to be particularly responsive to faces. If the surgeon cut this region out, it could make big problems for the patient.\n",
    "\n",
    "So, the surgeon presented a number of visual stimuli for the patient to look at. They placed a strip of electrodes over the general area where we'd expect the patient's FFA to be (along with a larger grid over the right hemisphere). The subject viewed images of faces as well as objects.\n",
    "\n",
    "Here are examples of two potential visual stimuli:\n",
    "\n",
    "Face:\n",
    "<img src=\"http://pngimg.com/upload/face_PNG5660.png\" alt=\"face\" style=\"width: 100px;\"/>\n",
    "\n",
    "Object:\n",
    "<img src=\"http://i74.photobucket.com/albums/i241/cmucam/Black_Stapler_zpsc3024407.jpg\" alt=\"object\" style=\"width: 100px;\"/>\n",
    "\n",
    "\n",
    "Our task will be to analyze the data collected from these two types of visual stimuli, in order to determine if we can identify the electrode that corresponds to the Fusiform Face Area.\n",
    "\n",
    "First, let's take a look at our ECoG grid to see where these electrodes are located..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "import neurods as nds\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datascience as ds\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll load the raw data that we'll use today..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# --- Set path ---\n",
    "path_data = '/home/shared/cogneuro-connector/data/midterm/proc/'\n",
    "# --- Raw data ---\n",
    "raw = mne.io.Raw(path_data + 'ecog-raw.fif', preload=True)\n",
    "\n",
    "# --- Event time information ---\n",
    "# As a pandas dataframe\n",
    "mtime = pd.read_csv(path_data + 'meta_time.csv', index_col=0)\n",
    "# Or as a datascience table (use whichever you like)\n",
    "mtime_tab = ds.Table.read_table(path_data + 'meta_time.csv', index_col=0)\n",
    "\n",
    "# --- Image and layout of the electrode grid ---\n",
    "im = plt.imread(path_data + 'brain.png')\n",
    "melec = pd.read_csv(path_data + 'meta_elec.csv', index_col=0)\n",
    "layout = mne.channels.read_layout('channel_layout.lout', path_data,\n",
    "                                  scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then make a quick plot of all the electrodes for this ECoG patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def plot_ecog_layout(layout, im, textcolor='r'):\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(im)\n",
    "    for _, (ch, _, x, y) in  melec.iterrows():\n",
    "        ax.scatter(x, y, c='r', s=60)\n",
    "        ax.annotate(ch, (x, y), (x-5, y-5),\n",
    "                    rotation=0, fontsize=16, color=textcolor)\n",
    "#     _ = plt.setp(ax.lines, visible=False)\n",
    "#     _ = plt.setp(ax.texts, size=16, color='r')\n",
    "    ax.set_axis_off()\n",
    "    return fig\n",
    "fig = plot_ecog_layout(layout, im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Don't forget you can switch on interactive mode with:\n",
    "%matplotlib notebook\n",
    "\n",
    "# And inline mode with:\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, most of the grid covers the right hemisphere, however that strip to the bottom left is important. It's the one that we think covers the FFA.\n",
    "\n",
    "# Loading and plotting raw data\n",
    "First, we need to get a high-level view of the dataset and drop any channels that look bad.\n",
    "\n",
    "* Plot the raw data we've loaded above. Scan through the entire session of data.\n",
    "* There is a noisy channel in there, mark its channel name, and put it in a list.\n",
    "* Finally, drop the channel from the ecog data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n",
    "_ = raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Put your noisy channel in a list (and drop it), here:\n",
    "\n",
    "### STUDENT ANSWER\n",
    "drop_chan = ['G23']\n",
    "raw.drop_channels(drop_chan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got clean channels, it's time to calculate the evoked activity in response to each type of visual stimulus. The visual stimuli are coded like this:\n",
    "\n",
    "- Faces : 7\n",
    "- Objects : 3\n",
    "\n",
    "We'll use event timing information in order to slice up our data and visualize how the brain responds to the pictures:\n",
    "\n",
    "* Create an MNE events array using the time information in `mtime`.\n",
    "    * Create one vector of event onsets in samples. Note that the event onsets in `mtime` are in seconds, not samples.\n",
    "    * Create a dictionary that maps the event type names (faces and objects) onto unique event type integers (7 and 3)\n",
    "    * Extract from mtime the vector that has one event type integer per event, which designates what event type that event was.\n",
    "    * Create a vector of 0s that has the same length as the above two vectors.\n",
    "    * Combine these three things into an MNE events array of shape `(n_events, 3)`\n",
    "    * Make sure that this array has a dtype of `int`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n",
    "# ID Dictionary\n",
    "event_id = {'object': 3, 'face': 7}\n",
    "\n",
    "# Convert to samples\n",
    "event_ixs = mtime_tab['start'] * raw.info['sfreq']\n",
    "zeros = np.zeros_like(event_ixs)\n",
    "ids = mtime['trial_type']\n",
    "events = np.vstack([event_ixs, zeros, ids]).T.astype(int)\n",
    "events[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epochs ERPs\n",
    "Now that we have event times in a form MNE can use, let's look at the evoked activity.\n",
    "\n",
    "* Make a copy of the `Raw` object (using the `.copy()` method).\n",
    "* Filter this copy between 1 and 30 Hz\n",
    "* Using the events array above, turn the `Raw` object into an `Epochs` object.\n",
    "  * Include times from -.3 to .8 seconds\n",
    "  * Include a baseline from -.3 to -.05 seconds (use the `baseline` parameter)\n",
    "  * Make sure to include the event ID dictionary you created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n",
    "# First filter between 1Hz and 30Hz\n",
    "raw_ep = raw.copy()\n",
    "raw_ep.filter(1, 30)\n",
    "\n",
    "# Now create epochs\n",
    "epochs = mne.Epochs(raw_ep, events, event_id, tmin=-.3, tmax=.8,\n",
    "                    baseline=(-.3, -.05))\n",
    "# epochs.save(path_data + 'epochs_filt-epo.fif')  # Used to create the original files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you weren't able to create the epochs data above, here we are loading the correct epochs data below. You can use this to continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs = mne.read_epochs(path_data + 'epochs_filt-epo.fif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create an MNE `Evoked` object by using the `average` method of the `Epochs` object.\n",
    "  * Create one `Evoked` object for each event type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "av1 = epochs['object'].average()\n",
    "av2 = epochs['face'].average()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the evoked activity:\n",
    "* Plot a topomap of the evoked activity using `mne.viz.plot_evoked_topo`.\n",
    "    * Use the layout supplied above as the input to the `layout` parameter,  and the image of the brain given above as the `fig_background` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "### STUDENT ANSWER\n",
    "_ = mne.viz.plot_evoked_topo([av1, av2], layout=layout, fig_background=im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a visualization of some individual channels. Try looking at the ERP for channels 'IO02' and 'IO03' (at indices 55 and 56).\n",
    "  * To do this, use the function `mne.viz.plot_compare_evokeds`, this will plot the evoked activity in each condition for that channel.\n",
    "  * This function will take a dictionary where each key is the name of an event type, and the value is an `Evoked` object. E.g.: `dict(event_type_1=av_1, event_type_2=av_2)`. It is also to simply pass a list of `Evoked` objects.\n",
    "  * Note: You can plot an individual channel using the `picks` parameter...note that it requires a list of integers, specifying channel indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ixs_plt = [55, 56]\n",
    "\n",
    "### STUDENT ANSWER\n",
    "for ix in ixs_plt:\n",
    "    _ = mne.viz.plot_compare_evokeds({'object': av1, 'face': av2}, picks=[ix])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Does it seem like there are differences between these two conditions in either of these two electrodes? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-frequency representation\n",
    "Maybe there are some differences, but it's hard to tell. Let's turn to a signal in the data that is much more closely-tied to brain activity: high-frequency activity.\n",
    "\n",
    "* Make another copy of the `Raw` data.\n",
    "* Use this copy along with the event timings to create another `Epochs` object from the raw data, this time without any filtering of the raw data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n",
    "raw_tfr = raw.copy()\n",
    "epochs = mne.Epochs(raw_tfr, events, event_id,\n",
    "                    tmin=-.3, tmax=.5, preload=True)\n",
    "# epochs.save(path_data + 'epochs_tfr-epo.fif')  # Used to create the original files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, in case you weren't able to do this correctly, here's the data that you should now have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs = mne.read_epochs(path_data + 'epochs_tfr-epo.fif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Then, use morlet wavelets to create a time-frequency representation of the `Epochs` data.\n",
    "* **for each event type**:\n",
    "    * You should use the `tfr_morlet` function\n",
    "    * Use 50 linearly-spaced frequencies from 10 to 150 Hz (use the `np.linspace` function.)\n",
    "    * Use `n_cycles=5`.\n",
    "    * Remember you can take a subset of the epochs belonging to a single event type by passing it as a string to the `epochs` object, e.g. `epochs['my_event_type']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n",
    "freqs = np.linspace(10, 150, 50)\n",
    "tfr_face = nds.tfr.tfr_morlet(epochs['face']._data, epochs.info['sfreq'], freqs,\n",
    "                              n_cycles=5.)\n",
    "tfr_object = nds.tfr.tfr_morlet(epochs['object']._data, epochs.info['sfreq'], freqs,\n",
    "                               n_cycles=5.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Calculate mean TFR for each condition by averaging across trials\n",
    "* then use the result to create an `AverageTFR` object for each condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n",
    "# Calculate the average TFR w/in each condition\n",
    "tfr_a_1 = tfr_face.mean(0)\n",
    "tfr_a_2 = tfr_object.mean(0)\n",
    "\n",
    "tfr_a_1 = mne.time_frequency.AverageTFR(epochs.info, tfr_a_1, epochs.times, freqs, epochs._data.shape[0])\n",
    "tfr_a_2 = mne.time_frequency.AverageTFR(epochs.info, tfr_a_2, epochs.times, freqs, epochs._data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, make a topographic map of the TFR for each condition.\n",
    "    * Use the `plot_topo` method of the `AverageTFR` object you've created. \n",
    "    * Use a baseline of `(None, 0)`\n",
    "    * set `mode='zscore'`\n",
    "    * set the vmin/vmax to -3 and 3\n",
    "    * Don't forget to set the image of the brain as the `fig_background`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "vmin, vmax = -3, 3\n",
    "### STUDENT ANSWER\n",
    "_ = tfr_a_1.plot_topo(picks=range(len(tfr_a_1.ch_names)), layout=layout,\n",
    "                      baseline=(None, 0), mode='zscore', vmin=vmin, vmax=vmax,\n",
    "                      fig_background=im)\n",
    "\n",
    "_ = tfr_a_2.plot_topo(picks=range(len(tfr_a_2.ch_names)), layout=layout,\n",
    "                      baseline=(None, 0), mode='zscore', vmin=vmin, vmax=vmax,\n",
    "                      fig_background=im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, calculate the difference between the two `AverageTFR` objects (you can directly subtract the two).\n",
    "* Make a topo plot of this result as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "### STUDENT ANSWER\n",
    "diff = tfr_a_2 - tfr_a_1\n",
    "_ = diff.plot_topo(picks=range(len(diff.ch_names)), layout=layout,\n",
    "                   baseline=(None, 0), mode='zscore', vmin=vmin, vmax=vmax,\n",
    "                   fig_background=im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like those electrodes over FFA seem to be doing something. Let's investigate further.\n",
    "\n",
    "* Make a TFR plot of channels \"IO02\" and \"IO03\" for the difference between the two conditions (the same ones we just plotted above).\n",
    "  * Use the `plot` method of the `AverageTFR` obects.\n",
    "  * Set the mode to `'zscore'`, the baseline to `(None, 0)`, and the vmin/vmax to -10 and 10, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mode = 'zscore'\n",
    "baseline = (None, 0)\n",
    "vmin, vmax = -10, 10\n",
    "### STUDENT ANSWER\n",
    "_ = diff.plot(ixs_plt, baseline=baseline, mode=mode, vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How do the differences between these TFRs compare with the ERPs that we calculated earlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n",
    "# There should be a reversal in the direction of the TFR for these two\n",
    "# electrodes. One has a bigger response for faces, the other has a bigger\n",
    "# response for objects. This is similar to the fact that ERPs showed opposite\n",
    "# trends (in terms of which line was above the other), but this is easier\n",
    "# to interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid memory getting overloaded, delete the two TFR objects that you created above. These take up too much memory. Below we've shown the code for doing this, but you might need to rename the variables depending on what you called them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del tfr_face\n",
    "del tfr_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-frequency amplitude\n",
    "It looks like the majority of the differences are in the high-frequencies (>40Hz or so). Let's focus on that and look at the effects.\n",
    "\n",
    "* On the raw data, use the `nds.tfr.extract_amplitude` function to extract 10 linearly-spaced frequencies from 70 to 150 Hz. (use `np.linspace`)\n",
    "* Then create an `Epochs` object from this high-frequency ampitude using the same event times above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n",
    "freqs = np.linspace(70, 150, 10)\n",
    "hfa = nds.tfr.extract_amplitude(raw, freqs)\n",
    "epochs_hfa = mne.Epochs(hfa, events, event_id, tmin=-.3, tmax=.5)\n",
    "# epochs_hfa.save(path_data + 'epochs_hfa-epo.fif')  # Used to create the original files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you were not able to create the epochs and extract high-frequency amplitude above, here is the epochs file that you'll need to finish this section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs_hfa = mne.read_epochs(path_data + 'epochs_hfa-epo.fif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create an `Evoked` object for each condition type.\n",
    "* Calculate the difference between the two `Evoked` objects\n",
    "* Plot this difference as a topo plot on the brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "### STUDENT ANSWER\n",
    "av_face = epochs_hfa['face'].average()\n",
    "av_object = epochs_hfa['object'].average()\n",
    "diff = av_face - av_object\n",
    "_ = diff.plot_topo(layout=layout, fig_background=im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the two electrodes to the bottom left are again showing the only effects. Let's take a look at them:\n",
    "\n",
    "* Finally, use the `mne.viz.plot_compare_evokeds` function to compare the evoked high-frequency activity between the two conditions for an electrode.\n",
    "  * Do this for the two electrodes we visusalized above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "### STUDENT ANSWER\n",
    "for ix in ixs_plt:\n",
    "    _ = mne.viz.plot_compare_evokeds({'face': av_face, 'object': av_object},\n",
    "                                     picks=[ix])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Extra credit - Comparing variance\n",
    "As a bonus, let's compre how noisy the raw ERPs are compared with the evoked high-frequency activity. Below we'll load the `Epochs` objects associated with each one, and take a subset of trials corresponding to faces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs_hfa = mne.read_epochs(path_data + 'epochs_hfa-epo.fif', preload=True)\n",
    "epochs_hfa = epochs_hfa['face'].crop(-.2, .5)\n",
    "\n",
    "epochs_raw = mne.read_epochs(path_data + 'epochs_filt-epo.fif', preload=True)\n",
    "epochs_raw = epochs_raw['face'].crop(-.2, .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For each `Epochs` object, calculate its mean **and** its standard error across trials. You can use the `nds.stats.standard_error` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n",
    "mean_hfa = epochs_hfa._data.mean(axis=0)\n",
    "se_hfa = nds.stats.standard_error(epochs_hfa._data, axis=0)\n",
    "\n",
    "mean_raw = epochs_raw._data.mean(axis=0)\n",
    "se_raw = nds.stats.standard_error(epochs_raw._data, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Finally, for the two active electrodes that we plotted above, make a plot showing the mean +/- the standard error for each data type (one for HFA, one for raw data).\n",
    "  * Plot the raw data with `ax1` and the HFA data with `ax2`.\n",
    "  * use the `ax.fill_between` function. This will accept a vector of x-values to plot (the `times` in our epochs objects), a vector of lower y-values to plot (the mean - the standard error), and a vector of upper y-values to plot (the mean + the standard error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "### STUDENT ANSWER\n",
    "for ix in ixs_plt:\n",
    "    ax1.fill_between(epochs_raw.times, mean_raw[ix] - se_raw[ix],\n",
    "                    mean_raw[ix] + se_raw[ix])\n",
    "    ax2.fill_between(epochs_hfa.times, mean_hfa[ix] - se_hfa[ix],\n",
    "                    mean_hfa[ix] + se_hfa[ix])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Which type of data seems to have a more clear difference between the two conditions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
