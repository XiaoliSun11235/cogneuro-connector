{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - A naturalistic reading  experiment\n",
    "\n",
    "We now switch gears to another experiment. In this experiment, subjects read multiple stories in the scanner. The stories were presented one word at a time, with the words appearing at the rate of natural speech. Each word was presented at the center of the screen by itself, for a few hundred milliseconds. So in every TR, subjects read about 4 to 15 words. \n",
    "\n",
    "For these words, one can extract multiple features. For example, some of the features can relate to the semantic properties of those words. We will not deal with such features today. We will look at only one type of features for these words: The letters that compose the words. Our feature space is a 26 dimensional space in which each dimension corresponds to a letter in the alphabet. At every TR, we count how many times each letter occured. \n",
    "\n",
    "For example, if during one TR the subject reads:\n",
    "\n",
    "\"it \n",
    "\n",
    "was \n",
    "\n",
    "the \n",
    "\n",
    "first \n",
    "\n",
    "time \n",
    "\n",
    "I \n",
    "\n",
    "saw\n",
    "\n",
    "something\n",
    "\n",
    "so\"\n",
    "\n",
    "then the feature dimension corresponding to the letter \"s\" will have a count of 5, the feature corresponding to \"t\" will have 5, the feature corresponding to \"a\" will have 2, the feature corresponding to \"e\" will have 3, etc. E.g.:\n",
    "\n",
    "| a        |    ...       | e  | ...      | s          | t  |\n",
    "| ------------- |:-------------:| -----:|:-------------:| -----:|:-------------:|\n",
    "| 2     |  ... | 3 | ...  |5 | 5 |\n",
    "\n",
    "\n",
    "We would like to learn a model that predicts the activity in the brain as a function of the letters that are read by the subject. Letters are used across words of all meanings, so you can see how this letter model captures low level properties rather than high level meaning. Thus it may be a good model for brain mechanisms related to processing letters rather than semantics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import neurods as nds\n",
    "import numpy as np\n",
    "import h5py, os\n",
    "import matplotlib.pyplot as plt\n",
    "# Configure defaults for plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.aspect'] = 'auto'\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Loading data\n",
    "\n",
    "Here, we load the data. For simplicity, the data has already been normalized for us.\n",
    "\n",
    "We will plot both the brain data and the letter features.\n",
    "\n",
    "Like the example we saw in class, the data is divided into training data and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading the design\n",
    "basedir = os.path.join(nds.io.data_list['fmri'],'reading')\n",
    "design = h5py.File(os.path.join(basedir,'s03_X_v2.hdf'))\n",
    "X_train = design['X_train'][:]\n",
    "X_test = design[\"X_test\"][:]\n",
    "\n",
    "# load the data\n",
    "import cortex\n",
    "sub, xfm = 'S3', 's03_reading'\n",
    "mask = cortex.db.get_mask(sub, xfm, 'thin')\n",
    "data = h5py.File(os.path.join(basedir,'s03_data_v2.hdf'))\n",
    "Y_train = data[\"Y_train\"][:]\n",
    "Y_test = data[\"Y_test\"][:]\n",
    "\n",
    "del data, design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing X_train and X_test\n",
    "\n",
    "- print the shape of the X_train and X_test function\n",
    "- use plt.imshow to show both matrices.\n",
    "- what does the column and row of each of X_train and X_test correspond to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the X matrices.\n",
    "\n",
    "Run the following cells to normalize the feature matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "X_train = zscore(X_train, axis = 0)\n",
    "X_test = zscore(X_test, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Y_train and Y_test\n",
    "\n",
    "- print the shape of the Y_train and Y_test function\n",
    "- DO **NOT** USE imshow here because you might run into memory issues.\n",
    "- what does the column and row of each of Y_train and Y_test correspond to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Convolution of the design matrix\n",
    "\n",
    "The TR here is 2. \n",
    "\n",
    "- Use the function in the package *neurods* to estimate the hrf\n",
    "- Plot the hrf\n",
    "- Use the np.convolve function to obtain conv_X_train. (Remember to trim the matrix properly).\n",
    "- Use plt.imshow to plot conv_X_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neurods.fmri import hrf as generate_hrf\n",
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Estimating voxel responses to features\n",
    "\n",
    "Here, we will again use linear regression to estimate the response of each feature to each voxel. \n",
    "\n",
    "- Implement OLS or copy the function you implemented earlier.\n",
    "- Use it to estimate the weights for all voxels.\n",
    "- Print the shape of the weights matrix. \n",
    "- What do the rows and columns correspond to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3.4 Predicting training data\n",
    "\n",
    "We will first predict the training data, and see how well the predicted data correlates with the real data.\n",
    "\n",
    "- compute Y_train_hat using the weights matrix and conv_X_train.\n",
    "- use compute_correlations below to compute the correlation of Y_train_hat and Y_train\n",
    "- make a flatmap of the correlation value over the brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "def compute_correlation(matrix_1, matrix_2):\n",
    "    matrix_1_norm = zscore(matrix_1, axis = 0)\n",
    "    matrix_2_norm = zscore(matrix_2, axis = 0)\n",
    "    prod = matrix_1_norm * matrix_2_norm\n",
    "    corr = np.mean(prod, axis = 0)\n",
    "    return corr\n",
    "\n",
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3.5 Predicting test data\n",
    "\n",
    "We will first predict the held out data, and see how well the predicted data correlates with the real held out data.\n",
    "\n",
    "- ATTENTION: you cannot use the matrix X_test to compute Y_test_hat. Remember, the weights you estimated are a function of the convolved design matrix. You need to use the hrf function above and np.convolve to obtain conv_X_test. And you need to trim it appropriately\n",
    "- compute Y_test_hat using the weights matrix and conv_X_test.\n",
    "- use compute_correlations below to compute the correlation of Y_test_hat and Y_test\n",
    "- make a flatmap of the correlation value over the brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "- Which regions appear to be predicted by letters the subject sees on the screen. Does that make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "timetravel": {
   "allowedContentTypes": [
    "text/plain"
   ],
   "enabled": false,
   "version": "1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
