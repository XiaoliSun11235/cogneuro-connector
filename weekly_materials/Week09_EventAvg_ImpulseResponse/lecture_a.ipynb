{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "We will introduce the way we formalize the organization of an experiment in a *design matrix*.\n",
    "\n",
    "# Goals\n",
    "\n",
    "* Compute averages of activity for different types of events in a localizer experiment.\n",
    "* Understand how responses to stimuli evolve over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import cortex as cx\n",
    "import neurods as nds\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Update neurods library\n",
    "nds.io.update_neurods()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Matplotlib defaults\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.aspect'] = 'auto'\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "Same as previously: load using nibabel, use get_data() method of the nibabel data object, transpose resulting data array, and zscore the data. For now, we will treat this as a generic data set (next week, we will learn more about the experiment that generated this data as we begin to actually analyze the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### TEACHER INFO\n",
    "nds.io.data_list['fmri'] = '/Users/mark/gdrive/neuro_connector/data/fMRI/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub, xfm = 'S2', 'S2_category_auto'\n",
    "basedir = os.path.join(nds.io.data_list['fmri'], 'categories')\n",
    "fname = os.path.join(basedir, 'sub01_categories1_1.nii.gz')\n",
    "mask = cx.db.get_mask(sub, xfm, type='cortical')\n",
    "data = nds.fmri.load_data(fname, mask=mask, standardize=True)\n",
    "print(\"Data dimensions are: \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### TEACHER INFO\n",
    "# Go over each HW function, what it does, and why it's a good idea to include each kwarg. \n",
    "# Also, note that there are nans in this array (just so you're aware that that could \n",
    "# screw things up)\n",
    "\n",
    "# (Load data)\n",
    "\n",
    "# Unmask\n",
    "data3d = nds.fmri.unmask(data[0], mask, bg_value=np.nan)\n",
    "data4d = nds.fmri.unmask(data, mask, bg_value=0)\n",
    "print(\"data3d dimensions are: \", data3d.shape)\n",
    "print(\"data4d dimensions are: \", data4d.shape)\n",
    "\n",
    "# Show\n",
    "_ = nds.viz.slice_3d_array(data3d, axis=0, cmap=plt.cm.RdBu_r, vmin=-3, vmax=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakout session\n",
    "> Two weeks ago, we made a plot of a single slice over time. Can you make a plot like that using nds.viz.slice_3d_array? (Plot the 8th slice over time). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n",
    "_ = nds.viz.slice_3d_array(data4d[:,8], 0, cmap='RdBu_r', vmin=-3, vmax=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick pycortex review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a volume\n",
    "vkw = dict(mask=mask, cmap='RdBu_r', vmin=-3, vmax=3)\n",
    "vol = cx.Volume(data[0], sub, xfm, **vkw)\n",
    "cx.webgl.show(vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show a flamtap\n",
    "# (If you get warnings about a module called shapely, ignore them; they are not important.)\n",
    "_ = cx.quickflat.make_figure(vol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load description of experiment \n",
    "The experiment we have been working with is a *localizer* experiment. It is designed to find areas of the brain that respond to particular visual categories of objects: faces, bodies, and places. It also reveals areas that respond more to objects than to scrambled versions of the same objects. This experiment is a simple replication of past work, and is commonly done as a first step to locate (or localize) a region of interest for further analysis in a subsequent experiment.\n",
    "\n",
    "For the localizer experiment, images from each category were presented in a block design. This means that images from the one category were shown one after another for a \"block\" of 20 seconds (10 TRs), followed by images from another category for a block of 20 seconds, and so on.\n",
    "\n",
    "<img src=\"figures/CategoryLocalizerDesign.001.png\" style=\"height: 400px;\">\n",
    "\n",
    "To analyze the data from this experiment at all, we need to know when the blocks for each category (faces, bodies, places, objects, and scrambled objects) began and ended. This information is stored in a *design matrix*, which we load below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "design = np.load(os.path.join(basedir, 'experiment_design.npz'))\n",
    "print('Experiment design variables: ', sorted(design.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conditions = design['conditions'].tolist()\n",
    "print('Conditions: ', conditions)\n",
    "design_run1 = design['run1']\n",
    "print('Design shape: ', design_run1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's often useful to show a design matrix as an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = plt.imshow(design_run1.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakout session\n",
    "> What are the dimensions here? Label the axes on the figure above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n",
    "_ = plt.imshow(design_run1.T)\n",
    "plt.xlabel('Time (TRs)', fontsize=14)\n",
    "plt.ylabel(\"Condition\", fontsize=14)\n",
    "_ = plt.yticks(range(5), conditions, fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find condition onsets\n",
    "Last week for homework you wrote a function to compute event-related averages of data, given condition onset times. Here's a good version of such a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nds.fmri.compute_event_avg??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we don't have explicit times, only logical indices for which timepoints belong to which conditions - so we need to compute when the condition onsets were to use our function, or we need to write a new function! Let's stick with the old one, as we'll use it later, and just find the condition onsets.\n",
    "\n",
    "> Find the onsets for each condition! And make your code into a re-usable function to find onsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n",
    "# NOTE: don't give more than 5-7 mins for this\n",
    "# Find condition onsets\n",
    "cond = 0\n",
    "onsets, = np.nonzero(design_run1[:, cond])\n",
    "onsets = [o for o in onsets if o-1 not in onsets]\n",
    "print(onsets)\n",
    "# Sanity check: did we do that right? \n",
    "plt.plot(design_run1[:,0])\n",
    "# or\n",
    "#plt.stem(design_run1[:,0])\n",
    "plt.plot(onsets, [1, 1], 'ro')\n",
    "plt.ylim([-.5, 1.5])\n",
    "\n",
    "# Code\n",
    "def get_onsets(design, cond):\n",
    "    \"\"\"Convert condition design matrix of 1s and 0s to condition onsets \n",
    "    for a specific condition\"\"\"\n",
    "    # Note fancy syntax to avoid tuple output\n",
    "    onsets, = np.nonzero(design[:, cond])\n",
    "    # Doesn't have to be an array, but why not\n",
    "    onsets = np.array([o for o in onsets if o-1 not in onsets])\n",
    "    return onsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "SO: Compute event averages for one condition!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cond = 'face'\n",
    "idx = conditions.index(cond)\n",
    "cond_onsets = get_onsets(design_run1, idx)\n",
    "n_time_points = 10\n",
    "cond_avg = nds.fmri.compute_event_avg(data, cond_onsets, n_time_points)\n",
    "print(\"Condition average (cond_avg) shape:\", cond_avg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show a bunch of flatmaps in sequence\n",
    "vkw = dict(mask=mask, cmap='RdBu_r', vmin=-2, vmax=2)\n",
    "for n, ca in enumerate(cond_avg):\n",
    "    cx.quickflat.make_figure(cx.Volume(ca, sub, xfm, **vkw), height=300)\n",
    "    plt.title('{n} TRs from onset'.format(n=n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show a movie of the event average timecourse\n",
    "vkw = dict(cmap='RdBu_r', vmin=-2, vmax=2)\n",
    "cx.webgl.show(cx.Volume(cond_avg, sub, xfm, **vkw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "How does the event average change over time? Why do you think this is? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakout session\n",
    "> Do this for all conditions; make your code compact, if you can! Keep your results in a dictionary called event_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n",
    "event_avg = {}\n",
    "event_avg_vol = {}\n",
    "conditions = ['body', 'face','object','place','scramble']\n",
    "n_time_points = 10\n",
    "vkw = dict(cmap='RdBu_r', vmin=-2, vmax=2)\n",
    "for cond in conditions:\n",
    "    onset = get_onsets(design_run1, conditions.index(cond))\n",
    "    event_avg[cond] = nds.fmri.compute_event_avg(data, onset, n_time_points)\n",
    "    event_avg_vol[cond] = cx.Volume(event_avg[cond], sub, xfm, **vkw)\n",
    "\n",
    "# Show multiple data sets in pycortex\n",
    "cx.webgl.show(event_avg_vol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute event averages with MOAR DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Unclear how loading 3 sessions will play with memory limits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get MORE DATA!\n",
    "fname = os.path.join(basedir, 'sub01_categories1_{n}.nii.gz')\n",
    "data_3runs = np.vstack([nds.fmri.load_data(fname.format(n=n), mask=mask, standardize=True) for n in [1,2,3]])\n",
    "print(\"Dimensions of the data: \", data_3runs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "design_3runs = np.vstack([design['run{n}'.format(n=n)] for n in [1,2,3]])\n",
    "print(\"Dimensions of the design matrix: \",design_3runs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n",
    "event_avg = {}\n",
    "event_avg_vol = {}\n",
    "conditions = ['body', 'face','object','place','scramble']\n",
    "n_time_points = 10\n",
    "vkw = dict(cmap='RdBu_r', vmin=-2, vmax=2)\n",
    "for cond, design in zip(conditions, design_3runs):\n",
    "    onsets = get_onsets(design_3runs, conditions.index(cond))\n",
    "    event_avg[cond] = nds.fmri.compute_event_avg(data_3runs, onsets, n_time_points)\n",
    "    event_avg_vol[cond] = cx.Volume(event_avg[cond], sub, xfm, **vkw)\n",
    "# Show movie\n",
    "cx.webgl.show(event_avg_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# again, perhaps overkill\n",
    "for n, tr in enumerate(event_avg['face']): \n",
    "    cx.quickflat.make_figure(cx.Volume(tr, sub, xfm, **vkw), height=300, )\n",
    "    plt.title('{n} TRs from onset'.format(n=n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
