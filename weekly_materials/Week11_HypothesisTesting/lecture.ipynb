{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "In the last lab, we went over how we can use linear regression to estimate how much a voxel responds to each stimulus in an experiment. We explained the regression problem and derive it's solution. We applied this analysis to real data.\n",
    "\n",
    "# Goals\n",
    "In this lab, we will study how to make sense of the weights that we estimate from data. The regression weights of a voxel for multiple stimuli might be representative of how that voxel responds to stimuli. Alternatively, the presence of noise could have lead to weights that do not correspond to how that voxel responds to the stimulus. To distinguish between these two cases, we need to run a hypothesis test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import neurods as nds\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "# Configure defaults for plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.aspect'] = 'auto'\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A hypothesis test is a statistical test that is used to determine whether there is enough evidence in a sample of data to infer that a certain condition is true in general. A hypothesis test examines two opposing hypotheses: the null hypothesis and the alternative hypothesis.\n",
    "\n",
    "In the context of brain imaging experiments, we typically have a test at every voxel. For every voxel, we could have a test between:\n",
    "- null hypothesis: this voxel is not responsive to faces\n",
    "- alternative hypothesis: this voxel is responsive to faces\n",
    "\n",
    "Another test could be done in the following way:\n",
    "- null hypothesis: this voxel is not responsive to faces more than to places\n",
    "- alternative hypothesis: this voxel is responsive to faces more than to places\n",
    "\n",
    "As you can see above, the test cannot be defined without a proper specification of its null and alternative hypotheses. Multiple tests could be done with the same data and the estimates we derive from it. A correct formulation of the test will guide the statistical procedure to be done and will help to arrive at a statistically sound hypothesis.\n",
    "\n",
    "In a typical fMRI experiment, we convolve the stimulus design matrix with a canonical hemodynamic response function and we use this to estimate weights for each condition at each voxel. We saw in class and in the homework how we can plot these estimated weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import inv\n",
    "def OLS(X,Y):\n",
    "    return np.dot(inv(np.dot(X.T,X)),np.dot(X.T,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling voxel responses\n",
    "\n",
    "Remember, we are using regression because we want to model different voxel responses to a set of stimuli. We learned how to take a stimulus time course and how to convolve it with the hemodynamic response. We then assumed that each voxel's activity was a linear combination of all the convolved time courses of the stimuli. We want to recover the parameters of the linear combination. Let's load some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "basedir = os.path.join(nds.io.data_list['fmri'],'categories')\n",
    "design = np.load(os.path.join(basedir,'experiment_design.npz'))\n",
    "print('Experiment design variables: ', design.keys())\n",
    "conditions = design['conditions'].tolist()\n",
    "print('Conditions: ', conditions)\n",
    "design_run1 = design['run1']\n",
    "for i, (cond, label) in enumerate(zip(design_run1.T, conditions)):\n",
    "    plt.plot(cond+i+0.2*i, label=label, lw=2)\n",
    "plt.title('Condition labels')\n",
    "_ = plt.legend(frameon=False, bbox_to_anchor=(1.4, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the zscore function while loading the data to normalize every block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cortex\n",
    "sub, xfm = 'S2', 'S2_category_auto'\n",
    "mask = cortex.db.get_mask(sub, xfm, type='cortical')\n",
    "fname = os.path.join(basedir, 'S2_categories1_{n}.nii.gz') #S2_categories1_{n}.nii.gz\n",
    "# fmri responses:\n",
    "Y = np.vstack([zscore(nds.fmri.load_data(fname.format(n=n), mask=mask, standardize=True)) for n in [1,2]])\n",
    "# stimuli:\n",
    "X = np.vstack([design[run] for run in ['run1','run2']])\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.imshow(Y)\n",
    "plt.title('Voxel responses')\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "for i, (cond, label) in enumerate(zip(X.T, conditions)):\n",
    "    plt.plot(cond+i+0.2*i, label=label, lw=2)\n",
    "plt.title('Condition labels')\n",
    "_ = plt.legend(frameon=False, bbox_to_anchor=(1.4, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to first build a design matrix that accounts for the hemodynamic response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neurods.fmri import hrf as generate_hrf\n",
    "t_hrf, hrf_1 = generate_hrf(tr=2)\n",
    "n, d = X.shape\n",
    "\n",
    "conv_X = np.zeros_like(X)\n",
    "for i in range(d):\n",
    "    conv_X[:,i] = np.convolve(X[:,i], hrf_1)[:n]\n",
    "    \n",
    "for i, (cond, label) in enumerate(zip(conv_X.T, conditions)):\n",
    "    plt.plot(cond+i+0.2*i, label=label, lw=2)\n",
    "    \n",
    "plt.title('Condition labels')\n",
    "_ = plt.legend(frameon=False, bbox_to_anchor=(1.4, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find the response of all the voxels in the brain to these 5 different conditions. Instead of a one dimensional output $Y$, we have a high dimensional output ${\\bf Y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weights = OLS(conv_X, Y)\n",
    "print('shape of weights is {}'.format(weights.shape))\n",
    "plt.imshow(weights)\n",
    "for idx, condition in enumerate(conditions):\n",
    "    vol = cortex.Volume(weights[idx], sub, xfm, mask = mask)\n",
    "    __  = cortex.quickflat.make_figure(vol)\n",
    "    plt.title(condition, fontsize = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What can we conclude from the above plots about where different categories are represented in the brain?\n",
    "- Can we trust very high weights more than small weights? How can we know what a good threshold is?\n",
    "\n",
    "In order to make inferences about brain representations from the result of our linear regression, we first need to estimate an appropriate statistic from the data. We will perform something called a t-test.\n",
    "\n",
    "First, we need to estimate the mean squared error. The weights above were obtained using matrices conv_X (the convolved design matrix), and Y (the data matrix). \n",
    "\n",
    "#### Breakout Session\n",
    "- First, use the weights estimated above to predict the activity $\\hat {\\bf Y}$.\n",
    "- Second, estimate the error ${\\bf Y-\\hat Y}$.\n",
    "- Then, estimate $\\boldsymbol \\sigma$, the mean squared error $\\sum_{i=0}^{N-1}(Y_i - \\hat Y_i)^2$. This will give you a vector corresponding to the mean squared error at every voxel.\n",
    "- Make a flatmap of $\\boldsymbol \\sigma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# start by using the variables conv_X and weights to estimate Y_hat\n",
    "# you should estimate a variable mse\n",
    "# then use to plot it the following:\n",
    "# vol = cortex.Volume(mse, sub, xfm, mask = mask)\n",
    "# __  = cortex.quickflat.make_figure(vol)\n",
    "# plt.title('mse', fontsize = 30)\n",
    "\n",
    "### STUDENT ANSWER\n",
    "Y_hat = conv_X * weights\n",
    "error = Y - Y_hat\n",
    "mse = np.sum((Y - Y_hat)**2, axis=0)\n",
    "vol = cortex.Volume(mse, sub, xfm, mask = mask)\n",
    "__  = cortex.quickflat.make_figure(vol)\n",
    "plt.title('mse', fontsize = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to define the notion of a contrast. In the homework, you were asked to subtract the weights for places from the weights for faces. This can be called a faces - places contrast. A contrast can be computed using a vector of d numbers. In our case, d=5 because we have 5 conditions.\n",
    "\n",
    "To compute the faces - places contrast, we can use the following contrast [0,1,0,-1,0]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b9a836fedf5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcontrast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcortex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVolume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxfm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m__\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mcortex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquickflat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'faces - places'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "c = np.array([0,1,0,-1,0])\n",
    "contrast = np.dot(c,weights)\n",
    "vol = cortex.Volume(contrast, sub, xfm, mask = mask)\n",
    "__  = cortex.quickflat.make_figure(vol)\n",
    "plt.title('faces - places', fontsize = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we use this contrast with? We want to find the regions that are more responsive to faces than to places. Therefore, for every voxel, we have the following:\n",
    "- null hypothesis: this voxel is not responsive to faces more than to places\n",
    "- alternative hypothesis: this voxel is responsive to faces more than to places\n",
    "\n",
    "Let's say a particular alternative hypothesis is actually correct, for example, a voxel $v$ does represent faces (in reality, we can never know this fact). \n",
    "\n",
    "If the alternative hypothesis is correct and our test doesn't reject the null hypothesis, we call this a type II error. In case where the null hypothesis is correct and we reject it, this is called a type I error, or a false positive.\n",
    "\n",
    "The probability of rejecting a null hypothesis when the alternative is correct, e.g. of correctly concluding that voxel $v$ does represent faces, is called the power of a test. The power depends on many properties of an experiment, of the test and of the hypotheses. Critical parameters of the experiment that can affect the power are for example the level of noise in the experiment, the effect size, the number of samples.\n",
    "\n",
    "We want a test that maximizes power. However, take the following test: always reject the null hypothesis. This test does maximize power, however, it also maximizes type I error. The opposite test: never reject the null hypothesis, minimize type I error, but it also makes the power equal to zero. We therefore want a test that maximizes power while keeping the false positive rate under an acceptable threshold.\n",
    "\n",
    "We cannot guarantee that we are making no type I errors. However, statistical tests have a guarantee on the probability of error. Depending on which test we use, we estimate a p-value for our observations. A p-value is defined as the probability of obtaining a result equal to or \"more extreme\" than what was actually observed, when the null hypothesis is true. We then reject the null hypothesis if the p-value is lower than some threshold. 0.05 is for example a common threshold for tests. If we reject with this rate, it means that the probability of us making a mistake is less than 0.05. \n",
    "\n",
    "Let's say the null hypothesis is actually true. Using a threshold of 0.05 actually means that if we could somehow repeat the experiment a large number of times, we would (falsely) reject the null hypothesis 5% of those times.\n",
    "\n",
    "A t-test allows us to estimate a statistic that can be readily converted into a p-value.\n",
    "\n",
    "For each voxel $v$, the t-statistic is the contrast value, divided by the standard error of the contrast. The standard error of the contrast is estimated as: $\\sqrt{\\hat{\\sigma_v}^2 c^T (X^T X)^{-1}c}$. Therefore the t-statistic at that voxel is \n",
    "\n",
    "$$ t_v = \\frac{c^T \\hat\\beta_v}{\\sqrt{\\hat{\\sigma}^2 c^T (X^T X)^{-1}c}}$$\n",
    "\n",
    "#### Breakout Session\n",
    "\n",
    "- Implement a function that takes as input the convolved design matrix, the weights of all voxels, the mse vector $\\boldsymbol \\sigma$ and the vector c. This function should output the value of the t-statistic for every voxel. \n",
    "- Use this function to estimate the t-statistic for each voxel with the contrast corresponding to faces - places\n",
    "- Produce a flatmap of those t-statistics \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# implement the function below, then use it with the existing variables:\n",
    "# t_statistic = t_stat(conv_X, weights, mse, [0,1,0,-1,0])\n",
    "# vol = cortex.Volume(t_statistic, sub, xfm, mask = mask)\n",
    "# __  = cortex.quickflat.make_figure(vol)\n",
    "# plt.title('t_statistic', fontsize = 30)\n",
    "from numpy.linalg import inv\n",
    "\n",
    "def t_stat(X, beta, mse, c):\n",
    "### STUDENT ANSWER\n",
    "    num = np.dot(c,beta)\n",
    "    ctXtXc = np.dot(np.dot(c, inv(np.dot(X.T,X)) ), c)\n",
    "    denum = np.sqrt(mse* ctXtXc)\n",
    "    return num/denum\n",
    "\n",
    "t_statistic = t_stat(conv_X, weights, mse, [0,1,0,-1,0])\n",
    "vol = cortex.Volume(t_statistic, sub, xfm, mask = mask)\n",
    "__  = cortex.quickflat.make_figure(vol)\n",
    "plt.title('t_statistic', fontsize = 30)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert t-statistics to p-values. The distribution of a t-statistic is determined by it's degree of freedom $\\nu$. For us, $\\nu$ corresponds to the number of datapoints used to estimate the statistic, i.e. the original number of samples (240)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEPCAYAAABRHfM8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d883278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEPCAYAAABGP2P1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGMhJREFUeJzt3XuUXnV97/H3N2CKyB0kQECLhIDcRURAhUG5BKsNXgEv\nh8LpOZwibU9tPcDq6iLL4lG7ansOshCCiKKW4OVAI4IECg8mjUCQBAIkJIJEchXkoqAQMvmeP/YT\nmBky99mz9/M879das57L7Ox8GCbzmf377f3bkZlIkrTJhKoDSJLqxWKQJPViMUiSerEYJEm9WAyS\npF4sBklSL6UWQ0RcFRHrIuKBAba5JCKWR8SiiDiszDySpMGVfcRwNXByf5+MiFOAfTJzX+Ac4PKS\n80iSBlFqMWTmPOCZATaZDlzT3PZuYPuImFRmJknSwKqeY5gMPNHj9arme5KkilRdDJKkmtmy4r9/\nFbBXj9d7Nt97jYhwUSdJGoHMjOFsPx5HDNH82JzZwH8BiIijgGczc11/O8pMP8bo46KLLqo8Qzt9\n1PHr+fOfJ3/1V8mkScnUqcm55ybf+U6yeHGyfn31+Vrpa9nKHyNR6hFDRPwb0AXsHBG/Ai4CJgKZ\nmTMz86aIeH9E/AJ4ATirzDxSu8uE226Diy+GFSvgzDNh3jyYMqXqZGolpRZDZn5iCNucV2YGqVM8\n/jicdx4sXw7/8A9w+umwZdWDxWpJTj53qK6urqojtJWqv57f/jYccQS8612weDF86lOtWwpVfy0F\nMdIxqPEWEdkqWaXx0t0Nf/3XMGcO/PCHcPDBVSdS3UQEOczJ5xb9nULS+vXFkcHTT8O998J221Wd\nSO3CYpBaUHd3MYewcSPceCNstVXVidROLAapxWQWw0fPPQc33wwTJ1adSO3GYpBazOWXw513Fqeh\nWgoqg5PPUgtZtAhOPBHmz4d99606jVrBSCafPV1VahF/+AOcdhpccomloHJ5xCC1iAsvhMceg+uu\nqzqJWomnq0pt6oEH4KqrikepbA4lSTWXCZ/5DHzhC7DbblWnUSewGKSamz27ODX17LOrTqJO4VCS\nVGMbNsAFF8BXvgJbbFF1GnUKjxikGrvmGpg0CU45peok6iSelSTVVHc3HHAAXHEFuOCoRsrrGKQ2\ncsMNsOOOcNxxVSdRp7EYpBrKhC99qbh2IYb1u540ehaDVENz58Lzz8MHP1h1EnUii0Gqoa99Dc49\nFyb4L1QVcPJZqpl162D//eGXv4Qddqg6jVqdk89SG7j6avjIRywFVccjBqlGNm6EKVPge9+DI46o\nOo3agUcMUoubOxe23dZSULUsBqlGvvMd+OQnq06hTudQklQTL70Ee+xR3KVtr72qTqN24VCS1MJu\nugkOOcRSUPUsBqkmHEZSXTiUJNXA888Xw0grVhTrI0ljxaEkqUXdfDMcc4yloHqwGKQauOEGOPXU\nqlNIBYeSpIqtX1/cjOfhh2H33atOo3bjUJLUgu64o1gbyVJQXVgMUsWuvx4+9KGqU0ivcihJqtDG\njbDnntBowNSpVadRO3IoSWoxDzwAb3iDpaB6sRikCt1yC0ybVnUKqbfSiyEipkXE0ohYFhHnb+bz\nO0fEzRGxKCIWR8SflZ1Jqouf/MRiUP2UOscQEROAZcD7gNXAAuD0zFzaY5uLgK0y88KI2AV4BJiU\nmRv67Ms5BrWV3/2uuNp57dpiOEkqQx3nGI4Elmfmisx8GZgFTO+zzVpg2+bzbYHf9C0FqR3dcQe8\n852Wgupny5L3Pxl4osfrlRRl0dOVwH9ExGpgG+C0kjNJteAwkuqq7GIYiguB+zPz+IjYB7g1Ig7J\nzOf7bjhjxoxXnnd1ddHV1TVuIaWxlFkUw+zZVSdRu2k0GjQajVHto+w5hqOAGZk5rfn6AiAz88s9\ntrkJ+EJm/mfz9X8A52fmvX325RyD2sajj8J73gOrVkEMa/RXGp46zjEsAKZExJsjYiJwOtD3d6Ql\nwAkAETEJmAo8VnIuqVKNBhx/vKWgeip1KCkzuyPiPGAORQldlZlLIuKc4tM5E/gicHVE3A8E8L8y\n8+kyc0lV21QMUh25JIY0zjKL23c2GjBlStVp1O7qOJQkqY9HHy0e99mn2hxSfywGaZzdcQd0dTm/\noPqyGKRx5vyC6s5ikMZRZlEMXoKjOrMYpHG0fDlMmABveUvVSaT+WQzSOLrzTucXVH8WgzSO5s+H\nd7+76hTSwCwGaRzNnw/HHFN1CmlgFoM0Tp56CtatgwMOqDqJNDCLQRon8+cX91/YYouqk0gDsxik\nceIwklqFxSCNE4tBrcJF9KRxsH497LQTrF4N221XdRp1EhfRk2pq0aJi0TxLQa3AYpDGwfz58K53\nVZ1CGhqLQRoHzi+olVgM0jiYPx+OPrrqFNLQWAxSyVatgpdecuE8tQ6LQSrZggXwjne4cJ5ah8Ug\nlWxTMUitwmKQSnbPPRaDWosXuEklyiwubFu6FCZNqjqNOpEXuEk184tfFBe1WQpqJRaDVCLnF9SK\nLAapRBaDWpHFIJXIYlArcvJZKsmGDbDDDsUFbttvX3UadSonn6Uaeegh2GsvS0Gtx2KQSuIwklqV\nxSCVxGJQq7IYpJJYDGpVTj5LJXjxxeKK56efhq22qjqNOpmTz1JNPPgg7LuvpaDWZDFIJbjvPnjb\n26pOIY2MxSCVYOFCi0Gtq/RiiIhpEbE0IpZFxPn9bNMVEQsj4sGIuKPsTFLZLAa1slInnyNiArAM\neB+wGlgAnJ6ZS3tssz0wHzgpM1dFxC6Z+dRm9uXks1pCd3exouqaNcWjVKU6Tj4fCSzPzBWZ+TIw\nC5jeZ5tPAD/MzFUAmysFqZU88gjsvruloNZVdjFMBp7o8Xpl872epgI7RcQdEbEgIj5dciapVA4j\nqdVtWXUAigyHA+8F3gD8LCJ+lpm/qDaWNDILF8Lhh1edQhq5sothFfCmHq/3bL7X00rgqcx8EXgx\nIn4KHAq8phhmzJjxyvOuri66urrGOK40egsXwuc+V3UKdapGo0Gj0RjVPsqefN4CeIRi8nkNcA9w\nRmYu6bHN/sBXgWnAHwF3A6dl5sN99uXks2ovE3beGZYs8XaeqoeRTD6XesSQmd0RcR4wh2I+46rM\nXBIR5xSfzpmZuTQibgEeALqBmX1LQWoVv/pVcbWzpaBWNuQjhuZv9n8MJLCi5ymn48EjBrWCG26A\nK6+EH/+46iRSYcyPGCLij4HPAu+nmAtYAwSwe0RMBn4M/GtmPj6CvFLb8YwktYPBhpL+CZgJfDYz\nN/T8RERsCRwPfBk4rZx4UmtZuBDOPLPqFNLouOy2NIb22gvuvBPe8paqk0iF0q58joh/bB4hbHq9\nXURcPdyAUjt78kn43e9g772rTiKNzlCvfN4SuDsiDomIEynWPPp5ebGk1rNwIRx2GMSwfjeT6mdI\np6tm5oURcRvFNQbPAMd6ZbLUmxPPahdDHUo6FrgE+DzQAL4aEXuUmEtqORaD2sVQh5L+GfhYZn4x\nMz8BXAncXl4sqfVYDGoXQzorKSK2yMzuPu/tnJm/KS3ZazN4VpJq6/nnYddd4bnn4HWvqzqN9KrS\nzkpqLm3x3uZf8t7me+NWClLd3X8/HHSQpaD2MJz7Mfxzn0dJTQ4jqZ2M5EY9nown9WExqJ2UfQc3\nqSNYDGonFoM0SuvXw9KlcPDBVSeRxobFII3Sww8Xy2BsvXXVSaSxMZxieL75+LsygkitymEktZsh\nF0NmHtvzUVLBYlC7cShJGiWLQe1m0GKIiB0jYnnEq2tGRsQ1EfHBcqNJ9bdxY3Fx22GHVZ1EGjuD\nFkNmPgPcA0wDiIhtgWMobuspdbRHH4Wddio+pHYx1KGkrwNnN5+fBnw/MzeWE0lqHffd5zCS2s9Q\n10q6AzgwInYCzqQoCqnjOb+gdjScyedvAxcD3Zn5aEl5pJZiMagdDekObk3fBH7Fq0NKUkfLLIrh\n8MOrTiKNrSEXQ2auiYhjgAdKzCO1jNWri8c9vJeh2syAQ0kRsU3P15m5IDNfan5unzKDSXW3aRgp\nXG9YbWawOYb7I+LjPd+IiK0i4mLglvJiSfXn/ILa1WDFcBJwVkTMiYgpETEdWAz8EeAlPepoFoPa\n1VDv+fw54IvAWuDkzHyo7GCbyeA9n1Ure+8Nt9wCU6dWnUTq35jf8zkitoyIC4H/AZwL3AtcEhH7\njTym1PqeeQZ+8xuYMqXqJNLYG2woaREwGTg8M2dm5qnAvwKzI+J/l55OqqlFi+CQQ2CCy1CqDQ32\nbX1mZp6Xmc9teiMzb6SYX3BcRx3L+QW1s8GK4b7NvZmZf8jMvwfoueqq1CksBrWzwYqhERGfi4jX\nTK9FxNSIOB9olJJMqjGLQe1swLOSImIi8EngE8BBwG+BALYBHgS+C1ybmetLD+pZSaqJ3/8edtkF\nnn0WJk6sOo00sJGclTTgkhjNH/hXA1dHxARgl+annnLZbXWqxYthv/0sBbWvwU5X3Soi/mdEXAr8\nOfB0Zv56OKUQEdMiYmlELGsOPfW33Tsi4uWI+PDQ40vjz2EktbvB5hi+BRxBcbXz+4GvDGfnzaOM\nS4GTgQOBMyJi/362+xIus6EWYDGo3Q1WDAdk5qcy8wrgo8B7hrn/I4HlmbkiM18GZgHTN7PdXwI/\nAH49zP1L485iULsbrBhe3vQkMzeMYP+TgSd6vF7ZfO8VEbEHcGpmfo1iYluqrQ0b4KGH4NBDq04i\nlWew+zEcGhG/bT4P4PXN1wFkZm43Bhn+D9Bz7sFyUG0tXQqTJ8O221adRCrPYGclbTHK/a8C3tTj\n9Z7N93o6ApjVvFBuF+CUiHg5M2f33dmMGTNeed7V1UVXV9co40nD4zCS6q7RaNBoNEa1jyGtrjri\nnUdsATwCvA9YA9wDnJGZS/rZ/mrgR5n5/zbzOa9jUOU++1nYdVe44IKqk0hDM+arq45WZnYD5wFz\ngIeAWZm5JCLOiYj/vrk/UmYeabQ8YlAnKPWIYSx5xKCqZcJOO8EjjxRHDVIrqN0Rg9ROHn20mHS2\nFNTuLAZpiO69F444ouoUUvksBmmILAZ1CotBGiKLQZ3CyWdpCDZuhB12gF/+Enbeueo00tA5+SyV\nZNkyeOMbLQV1BotBGgKHkdRJLAZpCCwGdRKLQRoCi0GdxMlnaRAbNhQTz6tWwfbbV51GGh4nn6US\nbFpq21JQp7AYpEE4jKROYzFIg7AY1GksBmkQFoM6jZPP0gDWry+W2l67FrbZpuo00vA5+SyNsYUL\nYd99LQV1FotBGsBdd8FRR1WdQhpfFoM0AItBnchikAZgMagTWQxSP9auheeeK+YYpE5iMUj9uOsu\neOc7YYL/StRh/JaX+nHXXXD00VWnkMafxSD1w/kFdSovcJM2Y8MG2HFHeOKJYmVVqVV5gZs0RhYv\nhr32shTUmSwGaTN+9rNi4lnqRBaDtBnz5sF73lN1CqkaFoPURyb89KcWgzqXxSD18fjj0N0NU6ZU\nnUSqhsUg9fHTn8Kxx0IM6zwOqX1YDFIfc+c6jKTOZjFIfWw6YpA6lcUg9bB2LTz5JBx0UNVJpOpY\nDFIPc+fCu9/twnnqbH77Sz3MneswkmQxSD00GhaDVHoxRMS0iFgaEcsi4vzNfP4TEXF/82NeRBxc\ndiZpc9auLRbNe/vbq04iVavUYoiICcClwMnAgcAZEbF/n80eA47NzEOBi4Ery8wk9ef226GrC7bc\nsuokUrXKPmI4EliemSsy82VgFjC95waZeVdmPtd8eRcwueRM0mbddhuceGLVKaTqlV0Mk4Enerxe\nycA/+P8cuLnURNJmZBbFcMIJVSeRqlebg+aIOB44C3h3f9vMmDHjleddXV10dXWVnkudYfny4nHf\nfavNIY1Wo9Gg0WiMah+l3sEtIo4CZmTmtObrC4DMzC/32e4Q4IfAtMx8tJ99eQc3leayy+Dee+Eb\n36g6iTS26ngHtwXAlIh4c0RMBE4HZvfcICLeRFEKn+6vFKSyOYwkvar0ez5HxDTg/1KU0FWZ+aWI\nOIfiyGFmRFwJfBhYAQTwcmYeuZn9eMSgUqxfD5MmwdKlxaPUTkZyxFB6MYwVi0Fluf12uPBCuPvu\nqpNIY6+OQ0lS7d14I3zgA1WnkOrDYlDHsxik3iwGdbRly+CFF+Cww6pOItWHxaCO9uMfF0cL3sZT\nepXFoI72ox/Bn/xJ1SmkevGsJHWsJ58srnReswZe//qq00jl8KwkaRiuvx6mTbMUpL4sBnWs738f\nPvaxqlNI9eNQkjrSU0/BlCmwejVsvXXVaaTyOJQkDdH118PJJ1sK0uZYDOpIs2bBxz9edQqpnhxK\nUsdZsaK4r/PKlbDVVlWnkcrlUJI0BNdcA6efbilI/anNHdyk8ZAJ3/wmXHdd1Umk+vKIQR1l3rzi\nuoW3v73qJFJ9WQzqKDNnwtlnuzaSNBAnn9Ux1q6Ft74VHnsMdtyx6jTS+HDyWRrAFVfAaadZCtJg\nPGJQR1i/Ht78ZrjtNjjwwKrTSOPHIwapH9/9Lhx0kKUgDYVHDGp7GzYUcwtf/zocd1zVaaTx5RGD\ntBmzZsHuu1sK0lB5xKC2tmFDMYR06aVwwglVp5HGn0cMUh8zZ8LkyfC+91WdRGodHjGobT37LOy3\nH8yZA4ceWnUaqRojOWKwGNS2/uZv4Pnn4corq04iVWckxeAiempLd91VTDo/8EDVSaTW4xyD2s6L\nL8JZZ8Ell8Ab31h1Gqn1OJSktvMXfwFPP+3S2hI4lCRxzTVw++2wYEHVSaTWZTGobcydC3/7t0Ux\nbLdd1Wmk1uUcg9rC/ffDRz4C114LBx9cdRqptVkMannz58NJJ8Fll3l1szQWLAa1tGuvhenT4Vvf\ngo9+tOo0UntwjkEt6be/hb/7O2g04NZb4bDDqk4ktY/SjxgiYlpELI2IZRFxfj/bXBIRyyNiUUT4\nT1z96u6Gb3+7WEZ740a4915LQRprpRZDREwALgVOBg4EzoiI/ftscwqwT2buC5wDXF5mJhUajUbV\nEYbl2Wfh8sth//2Lxx/8oLi/Ql3OPmq1r2ed+bWsXtlHDEcCyzNzRWa+DMwCpvfZZjpwDUBm3g1s\nHxGTSs7V8er+jy8Tli8v1jn68IeL23Leeit84xswbx4cfXTVCXur+9ezlfi1rF7ZcwyTgSd6vF5J\nURYDbbOq+d66cqOpSt3d8Pvfw5NPwtq1sGYNrF4Ny5bBQw8VH697HRx/PPzpnxaFsMMOVaeWOkNL\nTT5/4APFY9+VMcbydZn7rtPftXIl3HTT+PxdmfDSS/DCC0UZvPACrF8PW29drGW0227FHdZ22w2m\nToUPfhAOOKC4j0IM60J+SWOh1LWSIuIoYEZmTmu+vgDIzPxyj20uB+7IzOuar5cCx2Xmuj77cqEk\nSRqBuq2VtACYEhFvBtYApwNn9NlmNvAZ4LpmkTzbtxRg+P9hkqSRKbUYMrM7Is4D5lBMdF+VmUsi\n4pzi0zkzM2+KiPdHxC+AF4CzyswkSRpYyyy7LUkaH7VfEiMiPhoRD0ZEd0Qc3udzFzYvjFsSESdV\nlbFVRcRFEbEyIu5rfkyrOlOrGcoFnBq6iHg8Iu6PiIURcU/VeVpNRFwVEesi4oEe7+0YEXMi4pGI\nuCUith9sP7UvBmAx8CHgzp5vRsRbgY8DbwVOAS6L8ByWEfiXzDy8+fGTqsO0kqFcwKlh2wh0Zebb\nMrPvqe0a3NUU3489XQDclpn7AbcDFw62k9oXQ2Y+kpnLgb4/9KcDszJzQ2Y+DizntddIaHCW6cgN\n5QJODU/QAj+X6ioz5wHP9Hl7OvCt5vNvAacOtp9W/h/Q34VxGp7zmmtUfX0oh5jqZXMXcPo9ODoJ\n3BoRCyLiv1Udpk3suulMz8xcC+w62B+oxQVuEXEr0HMZjKD4Bvn7zPxRNanaw0BfW+Ay4POZmRFx\nMfAvwH8d/5TSK96VmWsi4o0UBbGk+Vuwxs6gZxzVohgy88QR/LFVwF49Xu/ZfE89DONreyVgCQ/P\nKuBNPV77PThKmbmm+fhkRFxPMVxnMYzOuoiYlJnrImI34NeD/YFWG0rqOR4+Gzg9IiZGxN7AFMCz\nGIah+U2yyYeBB6vK0qJeuYAzIiZSXMA5u+JMLSsito6IbZrP3wCchN+TIxG89mflnzWfnwn8+2A7\nqMURw0Ai4lTgq8AuwI0RsSgzT8nMhyPie8DDwMvAuelFGcP1T837X2wEHqdY9lxD1N8FnBXHamWT\ngOuby99sCXw3M+dUnKmlRMS/AV3AzhHxK+Ai4EvA9yPibGAFxdmcA+/Hn6WSpJ5abShJklQyi0GS\n1IvFIEnqxWKQJPViMUiSerEYJEm9WAySpF4sBklSLxaDNEIRcUTzpjITI+INzRtKHVB1Lmm0vPJZ\nGoWI+Dzw+ubHE5n55YojSaNmMUijEBGvo1hM7w/AMa7XpXbgUJI0OrsA2wDbAltVnEUaEx4xSKMQ\nEf8OXAvsDeyRmX9ZcSRp1Gq/7LZUVxHxaWB9Zs6KiAnAf0ZEV2Y2Ko4mjYpHDJKkXpxjkCT1YjFI\nknqxGCRJvVgMkqReLAZJUi8WgySpF4tBktSLxSBJ6uX/A8qrNXzfrtWKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d791ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nu = 240# Y.shape[0]\n",
    "from scipy.stats import t as tdistribution\n",
    "x = np.linspace(-10,10,num=10001)\n",
    "t_pdf = tdistribution.pdf(x, nu)\n",
    "plt.figure()\n",
    "plt.plot(x,t_pdf)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('P(X)')\n",
    "plt.figure()\n",
    "t_cdf = tdistribution.cdf(x, nu)\n",
    "plt.plot(x,t_cdf)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('P(X<=x)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the function tdistribution.cdf to estimate a p-value for the contrast at every voxel. Remember, cdf(x) is the probability of obtaining a value smaller than x. We want the p-value, which is the probability of obtaining a value higher than x, which is 1-cdf(x). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't_statistic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-98e39804a231>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp_statistic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_statistic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcortex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVolume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_statistic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxfm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m__\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mcortex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquickflat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p_statistic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcortex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVolume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_statistic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxfm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 't_statistic' is not defined"
     ]
    }
   ],
   "source": [
    "p_statistic = 1 - tdistribution.cdf(t_statistic,nu)\n",
    "vol = cortex.Volume(p_statistic, sub, xfm, mask = mask)\n",
    "__  = cortex.quickflat.make_figure(vol)\n",
    "plt.title('p_statistic', fontsize = 30)\n",
    "vol = cortex.Volume(-np.log10(p_statistic), sub, xfm, mask = mask)\n",
    "__  = cortex.quickflat.make_figure(vol)\n",
    "plt.title('p_statistic, log scale', fontsize = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What happens if we now threshold the brain at p<=0.05? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vol = cortex.Volume(p_statistic<=0.05, sub, xfm, mask = mask, vmin = -2, vmax = 2)\n",
    "__  = cortex.quickflat.make_figure(vol)\n",
    "plt.title('p<=0.05', fontsize = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 1998 (?), a group of researchers were able to show that a group of voxels in a dead salmon were responsive to a visual stimulus. Of course, this study was designed to show the perils of failing to control for multiple comparisons.\n",
    "\n",
    "Let's say there is a game in which a person has to pick a slot out of 100 and win a big prize. On the first try, that person guesses the correct slot.\n",
    "- What is the probability of that event happening by chance?\n",
    "- Would you be willing to suppose this person was previously told about which slot was correct?\n",
    "\n",
    "Now assume you have 10000 people playing this game. On their first try, 109 people guess the correct slot and win the prize.\n",
    "- Would you be willing to suppose these people were previously told about which slot was correct?\n",
    "- Would your assumption change if 5000 people guess the correct slot on their first try?\n",
    "- How does this relate to our problem?\n",
    "\n",
    "## Multiple comparison correction\n",
    "\n",
    "Multiple methods exist to perform multiple comparison correction. Familywise Error Rate (FWER) control the chance of getting any false positives. \n",
    "\n",
    "For example, when correcting for M multiple comparison, the Bonferroni correction consist of using a rate of $\\alpha/M$ instead of $\\alpha$.\n",
    "\n",
    "This is a conservative test: to avoid false positives, it makes the rate very small and thus might fail to reject many true positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-ce77724d0f64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0malpha_bonferroni\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcortex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVolume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_statistic\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxfm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m__\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mcortex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquickflat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y' is not defined"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "M = Y.shape[1]\n",
    "alpha_bonferroni = alpha/M\n",
    "vol = cortex.Volume(p_statistic<=alpha_bonferroni, sub, xfm, mask = mask, vmin = -2, vmax = 2)\n",
    "__  = cortex.quickflat.make_figure(vol)\n",
    "plt.title('Bonferroni correction', fontsize = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other, less conservative FWER methods exist. Another method is to correct for the False Discovery Rate (FDR), i.e. limit the proportion of false positives among the rejected tests. One famous method is the Benjamini Hochberg Procedure. We implement it for you below and use it to control the FDR at q = 0.05:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FDR_BH(p_vals, q):\n",
    "    M = p_val_sorted.shape[0]\n",
    "    # sort the p_values\n",
    "    p_val_sorted = np.sort(p_vals)\n",
    "    threshold = 0\n",
    "    # go the p_values in order and find the largest k where P(k) <= k/M*q\n",
    "    for idx,p in enumerate(p_val_sorted):\n",
    "        if p <= idx*q/M:\n",
    "            threshold = p\n",
    "        else\n",
    "            break\n",
    "    return threshold\n",
    "\n",
    "vol = cortex.Volume(p_statistic<=alpha_bonferroni, sub, xfm, mask = mask, vmin = -2, vmax = 2)\n",
    "__  = cortex.quickflat.make_figure(vol)\n",
    "plt.title('FDR correction', fontsize = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how this method rejects the null hypothesis at more voxels. Both methods control for multiple comparisons.\n",
    "\n",
    "## Predicting withheld data:\n",
    "\n",
    "Another method for testing if the weights of a learned model are meaningful and not due only to chance is to test them to predict new, unseen data. The idea is that if the weights we estimated are indicative of how the brain responds to the experimental conditions, then we can use them to predict the brain response for new data. Here, we introduce concepts that are very important for the statistics and machine learning fields:\n",
    "\n",
    "- Training set: is the part of the data you use to estimate your model. You can use this data as you wish. We will discuss overfitting next week and see why you might want to be careful with how much of the variance of this data you want your model to predict.\n",
    "- Test set: this test should remain untouched until the very end of your analysis, where you only use it to report your results. You should never go back to your analysis and change any parameters based on the performance of your model on the test set. \n",
    "\n",
    "We did not use yet the third run of our experiment. We will load it here and use it to test the performance of our model on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'S2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-47f7271f25a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcortex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxfm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'S2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'S2_category_auto'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcortex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxfm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cortical'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasedir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'S2_categories1_{n}.nii.gz'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#S2_categories1_{n}.nii.gz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# fmri responses:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/cortex/database.py\u001b[0m in \u001b[0;36mget_mask\u001b[0;34m(self, subject, xfmname, type)\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'masks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxfmname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxfmname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnibabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/cortex/database.py\u001b[0m in \u001b[0;36mget_paths\u001b[0;34m(self, subject)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0msurfpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilestore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"surfaces\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubjects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warning\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubjects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'S2'"
     ]
    }
   ],
   "source": [
    "import cortex\n",
    "sub, xfm = 'S2', 'S2_category_auto'\n",
    "mask = cortex.db.get_mask(sub, xfm, type='cortical')\n",
    "fname = os.path.join(basedir, 'S2_categories1_{n}.nii.gz') #S2_categories1_{n}.nii.gz\n",
    "# fmri responses:\n",
    "Y_test = np.vstack([zscore(nds.fmri.load_data(fname.format(n=n), mask=mask, standardize=True)) for n in [3]])\n",
    "# stimuli:\n",
    "X_test = np.vstack([design[run] for run in ['run3']])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "for i, (cond, label) in enumerate(zip(X_test.T, conditions)):\n",
    "    plt.plot(cond+i+0.2*i, label=label, lw=2)\n",
    "plt.title('Condition labels')\n",
    "_ = plt.legend(frameon=False, bbox_to_anchor=(1.4, 1))\n",
    "\n",
    "conv_X_test = np.zeros_like(X_test)\n",
    "for i in range(d):\n",
    "    conv_X_test[:,i] = np.convolve(X_test[:,i], hrf_1)[:n]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breakout Session\n",
    "\n",
    "Using the weights you have estimated before:\n",
    "- First, use conv_X_test to predict the activity $ {\\bf \\hat Y_{test}}$.\n",
    "- Second, estimate the error ${\\bf Y_{test}-\\hat Y_{test}}$.\n",
    "- Then, estimate $\\bf \\boldsymbol \\sigma_{test}$, the mean squared error $\\sum_{i=0}^{N-1}({Y_{test}}_i -  {\\hat Y_{test}}_i)^2$. This will give you a vector corresponding to the mean squared error at every voxel.\n",
    "- Compute the coefficient of determination, which estimates how much of the data is being predicted:\n",
    "    $R^2_{\\bf test} = 1 - \\frac{\\bf \\boldsymbol \\sigma_{test}}{var({\\bf Y_{test}})} $.\n",
    "    Since we have already normalized every voxel to have a variance of 1, you can simplity the computation to:\n",
    "    $R^2_{\\bf test} = 1 - \\bf \\boldsymbol \\sigma_{test} $\n",
    "- Produce a flatmap of $R^2_{\\bf test}$\n",
    "- Then, use the previously computed $\\boldsymbol \\sigma$ using training data to produce a flatmap of $R^2_{\\bf train} = 1 - \\bf \\boldsymbol \\sigma_{} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# start by using the variables conv_X_test and weights to estimate Y_hat_test\n",
    "# you should estimate a variable mse_test\n",
    "# then use to plot it the following:\n",
    "# vol = cortex.Volume(1-mse_test, sub, xfm, mask = mask)\n",
    "# __  = cortex.quickflat.make_figure(vol)\n",
    "# plt.title('R2 test', fontsize = 30)\n",
    "# then plot the training R2:\n",
    "# vol = cortex.Volume(1-mse, sub, xfm, mask = mask)\n",
    "# __  = cortex.quickflat.make_figure(vol)\n",
    "# plt.title('R2 train', fontsize = 30)\n",
    "\n",
    "### STUDENT ANSWER\n",
    "Y_hat_test = conv_X_test * weights\n",
    "error = Y_test - Y_hat_test\n",
    "mse_test = np.sum((Y_test - Y_hat_test)**2, axis=0)\n",
    "vol = cortex.Volume(1-mse_test, sub, xfm, mask = mask)\n",
    "__  = cortex.quickflat.make_figure(vol)\n",
    "plt.title('R2 test', fontsize = 30)\n",
    "then plot the training R2:\n",
    "vol = cortex.Volume(1-mse, sub, xfm, mask = mask)\n",
    "__  = cortex.quickflat.make_figure(vol)\n",
    "plt.title('R2 train', fontsize = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is the difference between the two plots?\n",
    "\n",
    "Additionally, one of the big fallacies in the fMRI litterature was something called double dipping. you should be careful to never use the same data to make and test your hypotheses! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
